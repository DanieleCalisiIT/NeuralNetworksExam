{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NN_colab.ipynb",
      "provenance": [],
      "mount_file_id": "https://github.com/DanieleCalisiIT/NeuralNetworksExam/blob/main/NN_colab.ipynb",
      "authorship_tag": "ABX9TyNImIXhKTKTI3FHa+s76ob/"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/MyDrive/NN/sota-music-tagging-models"
      ],
      "metadata": {
        "id": "VsMQY_hotVKo",
        "outputId": "d5d8cb4b-233d-453c-dc75-67369639f2b3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/NN/sota-music-tagging-models\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt --no-cache-dir"
      ],
      "metadata": {
        "id": "SwMyhJ6atab3",
        "outputId": "4251d203-94b0-4969-dab9-64dfe10b3684",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: audioread==2.1.8 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 1)) (2.1.8)\n",
            "Requirement already satisfied: essentia==2.1b6.dev184 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 2)) (2.1b6.dev184)\n",
            "Requirement already satisfied: fire==0.2.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 3)) (0.2.1)\n",
            "Collecting folium==0.2.1\n",
            "  Downloading folium-0.2.1.tar.gz (69 kB)\n",
            "\u001b[K     |████████████████████████████████| 69 kB 4.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio==1.25.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 5)) (1.25.0)\n",
            "Requirement already satisfied: h5py==2.10.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 6)) (2.10.0)\n",
            "Collecting imgaug==0.2.5\n",
            "  Downloading imgaug-0.2.5.tar.gz (562 kB)\n",
            "\u001b[K     |████████████████████████████████| 562 kB 8.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: librosa==0.7.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 8)) (0.7.2)\n",
            "Requirement already satisfied: llvmlite==0.31.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 9)) (0.31.0)\n",
            "Requirement already satisfied: matplotlib==3.1.3 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 10)) (3.1.3)\n",
            "Requirement already satisfied: numba==0.48.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 11)) (0.48.0)\n",
            "Collecting numpy==1.20\n",
            "  Downloading numpy-1.20.0-cp37-cp37m-manylinux2010_x86_64.whl (15.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 15.3 MB 42.6 MB/s \n",
            "\u001b[?25hCollecting pandas==1.0.4\n",
            "  Downloading pandas-1.0.4-cp37-cp37m-manylinux1_x86_64.whl (10.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.1 MB 54.0 MB/s \n",
            "\u001b[?25hCollecting scikit-learn==1.0.0\n",
            "  Downloading scikit_learn-1.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (23.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 23.1 MB 1.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy==1.3.3 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 15)) (1.3.3)\n",
            "Collecting six==1.15.0\n",
            "  Downloading six-1.15.0-py2.py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: SoundFile==0.10.3.post1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 17)) (0.10.3.post1)\n",
            "Requirement already satisfied: sox==1.3.7 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 18)) (1.3.7)\n",
            "Collecting tensorboard==2.8\n",
            "  Downloading tensorboard-2.8.0-py3-none-any.whl (5.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.8 MB 32.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow-estimator==2.1.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 20)) (2.1.0)\n",
            "Requirement already satisfied: termcolor==1.1.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 21)) (1.1.0)\n",
            "Collecting torch==1.10.0\n",
            "  Downloading torch-1.10.0-cp37-cp37m-manylinux1_x86_64.whl (881.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 881.9 MB 1.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torchaudio==0.3.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 23)) (0.3.0)\n",
            "Collecting tqdm==4.48.0\n",
            "  Downloading tqdm-4.48.0-py2.py3-none-any.whl (67 kB)\n",
            "\u001b[K     |████████████████████████████████| 67 kB 46.9 MB/s \n",
            "\u001b[?25hCollecting tf-estimator-nightly==2.8.0.dev2021122109\n",
            "  Downloading tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)\n",
            "\u001b[K     |████████████████████████████████| 462 kB 52.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from essentia==2.1b6.dev184->-r requirements.txt (line 2)) (3.13)\n",
            "Requirement already satisfied: Jinja2 in /usr/local/lib/python3.7/dist-packages (from folium==0.2.1->-r requirements.txt (line 4)) (2.11.3)\n",
            "Requirement already satisfied: scikit-image>=0.11.0 in /usr/local/lib/python3.7/dist-packages (from imgaug==0.2.5->-r requirements.txt (line 7)) (0.18.3)\n",
            "Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from librosa==0.7.2->-r requirements.txt (line 8)) (0.2.2)\n",
            "Requirement already satisfied: joblib>=0.12 in /usr/local/lib/python3.7/dist-packages (from librosa==0.7.2->-r requirements.txt (line 8)) (1.1.0)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa==0.7.2->-r requirements.txt (line 8)) (4.4.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.1.3->-r requirements.txt (line 10)) (1.4.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.1.3->-r requirements.txt (line 10)) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.1.3->-r requirements.txt (line 10)) (3.0.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.1.3->-r requirements.txt (line 10)) (2.8.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba==0.48.0->-r requirements.txt (line 11)) (57.4.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas==1.0.4->-r requirements.txt (line 13)) (2018.9)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==1.0.0->-r requirements.txt (line 14)) (3.1.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.7/dist-packages (from SoundFile==0.10.3.post1->-r requirements.txt (line 17)) (1.15.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard==2.8->-r requirements.txt (line 19)) (0.6.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard==2.8->-r requirements.txt (line 19)) (1.0.1)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard==2.8->-r requirements.txt (line 19)) (3.17.3)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard==2.8->-r requirements.txt (line 19)) (1.35.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard==2.8->-r requirements.txt (line 19)) (1.8.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard==2.8->-r requirements.txt (line 19)) (2.23.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard==2.8->-r requirements.txt (line 19)) (0.37.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard==2.8->-r requirements.txt (line 19)) (1.0.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard==2.8->-r requirements.txt (line 19)) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard==2.8->-r requirements.txt (line 19)) (3.3.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.10.0->-r requirements.txt (line 22)) (3.10.0.2)\n",
            "INFO: pip is looking at multiple versions of torch to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of termcolor to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting termcolor==1.1.0\n",
            "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
            "INFO: pip is looking at multiple versions of tensorflow-estimator to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting tensorflow-estimator==2.1.0\n",
            "  Downloading tensorflow_estimator-2.1.0-py2.py3-none-any.whl (448 kB)\n",
            "\u001b[K     |████████████████████████████████| 448 kB 49.4 MB/s \n",
            "\u001b[?25hINFO: pip is looking at multiple versions of tensorboard to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of sox to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting sox==1.3.7\n",
            "  Downloading sox-1.3.7-py2.py3-none-any.whl (34 kB)\n",
            "INFO: pip is looking at multiple versions of torch to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of termcolor to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of soundfile to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting SoundFile==0.10.3.post1\n",
            "  Downloading SoundFile-0.10.3.post1-py2.py3-none-any.whl (21 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. If you want to abort this run, you can press Ctrl + C to do so. To improve how pip performs, tell us what happened here: https://pip.pypa.io/surveys/backtracking\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. If you want to abort this run, you can press Ctrl + C to do so. To improve how pip performs, tell us what happened here: https://pip.pypa.io/surveys/backtracking\n",
            "INFO: pip is looking at multiple versions of tensorflow-estimator to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of six to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of scipy to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting scipy==1.3.3\n",
            "  Downloading scipy-1.3.3-cp37-cp37m-manylinux1_x86_64.whl (25.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 25.2 MB 23.8 MB/s \n",
            "\u001b[?25hINFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. If you want to abort this run, you can press Ctrl + C to do so. To improve how pip performs, tell us what happened here: https://pip.pypa.io/surveys/backtracking\n",
            "INFO: pip is looking at multiple versions of tensorboard to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of sox to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of scikit-learn to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of pandas to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of <Python from Requires-Python> to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of numpy to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of numba to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting numba==0.48.0\n",
            "  Downloading numba-0.48.0-1-cp37-cp37m-manylinux2014_x86_64.whl (3.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.5 MB 31.9 MB/s \n",
            "\u001b[?25hINFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. If you want to abort this run, you can press Ctrl + C to do so. To improve how pip performs, tell us what happened here: https://pip.pypa.io/surveys/backtracking\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. If you want to abort this run, you can press Ctrl + C to do so. To improve how pip performs, tell us what happened here: https://pip.pypa.io/surveys/backtracking\n",
            "INFO: pip is looking at multiple versions of soundfile to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of matplotlib to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting matplotlib==3.1.3\n",
            "  Downloading matplotlib-3.1.3-cp37-cp37m-manylinux1_x86_64.whl (13.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 13.1 MB 31.6 MB/s \n",
            "\u001b[?25hINFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. If you want to abort this run, you can press Ctrl + C to do so. To improve how pip performs, tell us what happened here: https://pip.pypa.io/surveys/backtracking\n",
            "INFO: pip is looking at multiple versions of six to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of scipy to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of llvmlite to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting llvmlite==0.31.0\n",
            "  Downloading llvmlite-0.31.0-cp37-cp37m-manylinux1_x86_64.whl (20.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 20.2 MB 33.1 MB/s \n",
            "\u001b[?25hINFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. If you want to abort this run, you can press Ctrl + C to do so. To improve how pip performs, tell us what happened here: https://pip.pypa.io/surveys/backtracking\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. If you want to abort this run, you can press Ctrl + C to do so. To improve how pip performs, tell us what happened here: https://pip.pypa.io/surveys/backtracking\n",
            "INFO: pip is looking at multiple versions of scikit-learn to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of pandas to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of numpy to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of numba to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of librosa to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting librosa==0.7.2\n",
            "  Downloading librosa-0.7.2.tar.gz (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 44.6 MB/s \n",
            "\u001b[?25hINFO: pip is looking at multiple versions of <Python from Requires-Python> to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. If you want to abort this run, you can press Ctrl + C to do so. To improve how pip performs, tell us what happened here: https://pip.pypa.io/surveys/backtracking\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. If you want to abort this run, you can press Ctrl + C to do so. To improve how pip performs, tell us what happened here: https://pip.pypa.io/surveys/backtracking\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. If you want to abort this run, you can press Ctrl + C to do so. To improve how pip performs, tell us what happened here: https://pip.pypa.io/surveys/backtracking\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. If you want to abort this run, you can press Ctrl + C to do so. To improve how pip performs, tell us what happened here: https://pip.pypa.io/surveys/backtracking\n",
            "INFO: pip is looking at multiple versions of matplotlib to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of imgaug to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of h5py to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting h5py==2.10.0\n",
            "  Downloading h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 33.6 MB/s \n",
            "\u001b[?25hINFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. If you want to abort this run, you can press Ctrl + C to do so. To improve how pip performs, tell us what happened here: https://pip.pypa.io/surveys/backtracking\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. If you want to abort this run, you can press Ctrl + C to do so. To improve how pip performs, tell us what happened here: https://pip.pypa.io/surveys/backtracking\n",
            "INFO: pip is looking at multiple versions of llvmlite to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of grpcio to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting grpcio==1.25.0\n",
            "  Downloading grpcio-1.25.0-cp37-cp37m-manylinux2010_x86_64.whl (2.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.4 MB 35.7 MB/s \n",
            "\u001b[?25hINFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. If you want to abort this run, you can press Ctrl + C to do so. To improve how pip performs, tell us what happened here: https://pip.pypa.io/surveys/backtracking\n",
            "INFO: pip is looking at multiple versions of librosa to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of folium to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of fire to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting fire==0.2.1\n",
            "  Downloading fire-0.2.1.tar.gz (76 kB)\n",
            "\u001b[K     |████████████████████████████████| 76 kB 46.1 MB/s \n",
            "\u001b[?25hINFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. If you want to abort this run, you can press Ctrl + C to do so. To improve how pip performs, tell us what happened here: https://pip.pypa.io/surveys/backtracking\n",
            "INFO: pip is looking at multiple versions of imgaug to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of h5py to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of essentia to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting essentia==2.1b6.dev184\n",
            "  Downloading essentia-2.1b6.dev184-cp37-cp37m-manylinux1_x86_64.whl (11.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 11.7 MB 20.8 MB/s \n",
            "\u001b[?25hINFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. If you want to abort this run, you can press Ctrl + C to do so. To improve how pip performs, tell us what happened here: https://pip.pypa.io/surveys/backtracking\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. If you want to abort this run, you can press Ctrl + C to do so. To improve how pip performs, tell us what happened here: https://pip.pypa.io/surveys/backtracking\n",
            "INFO: pip is looking at multiple versions of grpcio to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of audioread to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting audioread==2.1.8\n",
            "  Downloading audioread-2.1.8.tar.gz (21 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. If you want to abort this run, you can press Ctrl + C to do so. To improve how pip performs, tell us what happened here: https://pip.pypa.io/surveys/backtracking\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -u mtat_read.py run /content/drive/MyDrive/NN/MagnaTagATune/dataset/mp3/"
      ],
      "metadata": {
        "id": "NZ0C8R4OvB3C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "______________________________________________________________________________"
      ],
      "metadata": {
        "id": "xAUPHOp_vpLy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/MyDrive/NN"
      ],
      "metadata": {
        "id": "2ulKAn_byrFb",
        "outputId": "ab5a15f5-80cc-4db0-80bc-37135d946d43",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/NN\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/tae-jun/resemul"
      ],
      "metadata": {
        "id": "HAm4nFKEys0a",
        "outputId": "c0411103-157b-40a7-dfbd-ee79d568257e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'resemul'...\n",
            "remote: Enumerating objects: 61, done.\u001b[K\n",
            "remote: Counting objects: 100% (6/6), done.\u001b[K\n",
            "remote: Compressing objects: 100% (6/6), done.\u001b[K\n",
            "remote: Total 61 (delta 0), reused 0 (delta 0), pack-reused 55\u001b[K\n",
            "Unpacking objects: 100% (61/61), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/MyDrive/NN/resemul"
      ],
      "metadata": {
        "id": "-EWvYn_dzSqz",
        "outputId": "f536807d-a743-4958-95f6-f34b9a1b7222",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/NN/resemul\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "q5ULKOs1zDvD",
        "outputId": "46112dd5-22d3-4fb5-e47b-7f6f10b5770b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting Cython==0.27.3\n",
            "  Using cached Cython-0.27.3.tar.gz (1.8 MB)\n",
            "Collecting h5py==2.7.1\n",
            "  Using cached h5py-2.7.1.tar.gz (264 kB)\n",
            "Requirement already satisfied: jupyter==1.0.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 3)) (1.0.0)\n",
            "Collecting Keras==2.0.5\n",
            "  Using cached Keras-2.0.5.tar.gz (216 kB)\n",
            "Collecting numpy==1.14.1\n",
            "  Using cached numpy-1.14.1.zip (4.9 MB)\n",
            "Collecting pandas==1.0.1\n",
            "  Using cached pandas-1.0.1-cp37-cp37m-manylinux1_x86_64.whl (10.1 MB)\n",
            "Collecting scikit-learn==0.19.1\n",
            "  Using cached scikit-learn-0.19.1.tar.gz (9.5 MB)\n",
            "Collecting scipy==1.0.0\n",
            "  Using cached scipy-1.0.0.tar.gz (15.2 MB)\n",
            "Collecting tensorflow-gpu==1.13.1\n",
            "  Downloading tensorflow_gpu-1.13.1-cp37-cp37m-manylinux1_x86_64.whl (345.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 345.0 MB 4.0 kB/s \n",
            "\u001b[?25hCollecting matplotlib==2.2.0\n",
            "  Downloading matplotlib-2.2.0.tar.gz (37.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 37.2 MB 1.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from h5py==2.7.1->-r requirements.txt (line 2)) (1.15.0)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.7/dist-packages (from jupyter==1.0.0->-r requirements.txt (line 3)) (4.10.1)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.7/dist-packages (from jupyter==1.0.0->-r requirements.txt (line 3)) (5.3.1)\n",
            "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.7/dist-packages (from jupyter==1.0.0->-r requirements.txt (line 3)) (5.2.0)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.7/dist-packages (from jupyter==1.0.0->-r requirements.txt (line 3)) (7.7.0)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from jupyter==1.0.0->-r requirements.txt (line 3)) (5.6.1)\n",
            "Requirement already satisfied: qtconsole in /usr/local/lib/python3.7/dist-packages (from jupyter==1.0.0->-r requirements.txt (line 3)) (5.2.2)\n",
            "Collecting theano\n",
            "  Downloading Theano-1.0.5.tar.gz (2.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.8 MB 30.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from Keras==2.0.5->-r requirements.txt (line 4)) (3.13)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas==1.0.1->-r requirements.txt (line 6)) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from pandas==1.0.1->-r requirements.txt (line 6)) (2.8.2)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.13.1->-r requirements.txt (line 10)) (1.1.2)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.13.1->-r requirements.txt (line 10)) (3.17.3)\n",
            "Collecting keras-applications>=1.0.6\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 5.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.13.1->-r requirements.txt (line 10)) (1.0.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.13.1->-r requirements.txt (line 10)) (0.5.3)\n",
            "Collecting tensorflow-estimator<1.14.0rc0,>=1.13.0\n",
            "  Downloading tensorflow_estimator-1.13.0-py2.py3-none-any.whl (367 kB)\n",
            "\u001b[K     |████████████████████████████████| 367 kB 41.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.13.1->-r requirements.txt (line 10)) (0.37.1)\n",
            "Collecting tensorboard<1.14.0,>=1.13.0\n",
            "  Downloading tensorboard-1.13.1-py3-none-any.whl (3.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2 MB 22.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.13.1->-r requirements.txt (line 10)) (1.1.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.13.1->-r requirements.txt (line 10)) (0.8.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.13.1->-r requirements.txt (line 10)) (1.44.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib==2.2.0->-r requirements.txt (line 11)) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==2.2.0->-r requirements.txt (line 11)) (3.0.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==2.2.0->-r requirements.txt (line 11)) (1.4.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib==2.2.0->-r requirements.txt (line 11)) (3.10.0.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow-gpu==1.13.1->-r requirements.txt (line 10)) (3.3.6)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow-gpu==1.13.1->-r requirements.txt (line 10)) (1.0.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow-gpu==1.13.1->-r requirements.txt (line 10)) (4.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow-gpu==1.13.1->-r requirements.txt (line 10)) (3.7.0)\n",
            "Collecting mock>=2.0.0\n",
            "  Downloading mock-4.0.3-py3-none-any.whl (28 kB)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter==1.0.0->-r requirements.txt (line 3)) (5.3.5)\n",
            "Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter==1.0.0->-r requirements.txt (line 3)) (5.1.1)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter==1.0.0->-r requirements.txt (line 3)) (5.5.0)\n",
            "Requirement already satisfied: traitlets>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter==1.0.0->-r requirements.txt (line 3)) (5.1.1)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter==1.0.0->-r requirements.txt (line 3)) (2.6.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter==1.0.0->-r requirements.txt (line 3)) (57.4.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter==1.0.0->-r requirements.txt (line 3)) (0.7.5)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter==1.0.0->-r requirements.txt (line 3)) (4.8.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter==1.0.0->-r requirements.txt (line 3)) (4.4.2)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter==1.0.0->-r requirements.txt (line 3)) (1.0.18)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter==1.0.0->-r requirements.txt (line 3)) (0.8.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0->ipykernel->jupyter==1.0.0->-r requirements.txt (line 3)) (0.2.5)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter==1.0.0->-r requirements.txt (line 3)) (1.1.0)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter==1.0.0->-r requirements.txt (line 3)) (0.2.0)\n",
            "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter==1.0.0->-r requirements.txt (line 3)) (5.2.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter==1.0.0->-r requirements.txt (line 3)) (3.6.0)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets->jupyter==1.0.0->-r requirements.txt (line 3)) (4.3.3)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets->jupyter==1.0.0->-r requirements.txt (line 3)) (4.9.2)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->jupyter==1.0.0->-r requirements.txt (line 3)) (5.4.0)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->jupyter==1.0.0->-r requirements.txt (line 3)) (21.4.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->jupyter==1.0.0->-r requirements.txt (line 3)) (0.18.1)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter==1.0.0->-r requirements.txt (line 3)) (1.8.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter==1.0.0->-r requirements.txt (line 3)) (2.11.3)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter==1.0.0->-r requirements.txt (line 3)) (0.13.3)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel->jupyter==1.0.0->-r requirements.txt (line 3)) (22.3.0)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.7/dist-packages (from terminado>=0.8.1->notebook->jupyter==1.0.0->-r requirements.txt (line 3)) (0.7.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->notebook->jupyter==1.0.0->-r requirements.txt (line 3)) (2.0.1)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter==1.0.0->-r requirements.txt (line 3)) (0.7.1)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter==1.0.0->-r requirements.txt (line 3)) (0.4)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter==1.0.0->-r requirements.txt (line 3)) (1.5.0)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter==1.0.0->-r requirements.txt (line 3)) (0.8.4)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter==1.0.0->-r requirements.txt (line 3)) (4.1.0)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter==1.0.0->-r requirements.txt (line 3)) (0.6.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->jupyter==1.0.0->-r requirements.txt (line 3)) (21.3)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->jupyter==1.0.0->-r requirements.txt (line 3)) (0.5.1)\n",
            "Requirement already satisfied: qtpy in /usr/local/lib/python3.7/dist-packages (from qtconsole->jupyter==1.0.0->-r requirements.txt (line 3)) (2.0.1)\n",
            "Building wheels for collected packages: Cython, h5py, Keras, numpy, scikit-learn, scipy, matplotlib, theano\n",
            "  Building wheel for Cython (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for Cython: filename=Cython-0.27.3-cp37-cp37m-linux_x86_64.whl size=7307052 sha256=7a2b29acb859207cf941ccbd3e47f288321ef63dbf4272b77a67e63466d5ed60\n",
            "  Stored in directory: /root/.cache/pip/wheels/06/94/c9/ff7b5fcd077d417a795b9554da3b877502301c3307315481e0\n",
            "  Building wheel for h5py (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for h5py: filename=h5py-2.7.1-cp37-cp37m-linux_x86_64.whl size=3636815 sha256=d05ebe2f32c567bb852fa8e00da2a740a3e4c90fdf23794a12788902cf4753d1\n",
            "  Stored in directory: /root/.cache/pip/wheels/94/8d/48/e93a5045600d40dcf698750e02e650a52a46afe94a754d1e47\n",
            "  Building wheel for Keras (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for Keras: filename=Keras-2.0.5-py3-none-any.whl size=253391 sha256=6596e0d5829d45aeb429e057a03984f82e9b9aa7efcef9b547876224735e8b30\n",
            "  Stored in directory: /root/.cache/pip/wheels/f5/95/ac/4159953022b08e3f8952663e71142229375488a2a397a5aed8\n",
            "  Building wheel for numpy (setup.py) ... \u001b[?25lerror\n",
            "\u001b[31m  ERROR: Failed building wheel for numpy\u001b[0m\n",
            "\u001b[?25h  Running setup.py clean for numpy\n",
            "\u001b[31m  ERROR: Failed cleaning build dir for numpy\u001b[0m\n",
            "  Building wheel for scikit-learn (setup.py) ... \u001b[?25lerror\n",
            "\u001b[31m  ERROR: Failed building wheel for scikit-learn\u001b[0m\n",
            "\u001b[?25h  Running setup.py clean for scikit-learn\n",
            "  Building wheel for scipy (setup.py) ... \u001b[?25lerror\n",
            "\u001b[31m  ERROR: Failed building wheel for scipy\u001b[0m\n",
            "\u001b[?25h  Running setup.py clean for scipy\n",
            "\u001b[31m  ERROR: Failed cleaning build dir for scipy\u001b[0m\n",
            "  Building wheel for matplotlib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for matplotlib: filename=matplotlib-2.2.0-cp37-cp37m-linux_x86_64.whl size=10548401 sha256=77ad5af76e3a4bb267a83e5bedd5f4be030c056928c90069c0e93feae71ed977\n",
            "  Stored in directory: /root/.cache/pip/wheels/a0/a2/d0/7be703aeb6dcbf1d412213740bcc48a72627bdd727867fdfe6\n",
            "  Building wheel for theano (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for theano: filename=Theano-1.0.5-py3-none-any.whl size=2668111 sha256=0bb97b3d1adce21b71a5a170112bea7862e7139afdae0095f3567ade99827d52\n",
            "  Stored in directory: /root/.cache/pip/wheels/26/68/6f/745330367ce7822fe0cd863712858151f5723a0a5e322cc144\n",
            "Successfully built Cython h5py Keras matplotlib theano\n",
            "Failed to build numpy scikit-learn scipy\n",
            "Installing collected packages: numpy, scipy, mock, h5py, theano, tensorflow-estimator, tensorboard, keras-applications, tensorflow-gpu, scikit-learn, pandas, matplotlib, Keras, Cython\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.21.5\n",
            "    Uninstalling numpy-1.21.5:\n",
            "      Successfully uninstalled numpy-1.21.5\n",
            "    Running setup.py install for numpy ... \u001b[?25l\u001b[?25herror\n",
            "  Rolling back uninstall of numpy\n",
            "  Moving to /usr/bin/f2py\n",
            "   from /tmp/pip-uninstall-3tvpdwz_/f2py\n",
            "  Moving to /usr/local/bin/f2py\n",
            "   from /tmp/pip-uninstall-x36ba3nj/f2py\n",
            "  Moving to /usr/local/bin/f2py3\n",
            "   from /tmp/pip-uninstall-x36ba3nj/f2py3\n",
            "  Moving to /usr/local/bin/f2py3.7\n",
            "   from /tmp/pip-uninstall-x36ba3nj/f2py3.7\n",
            "  Moving to /usr/local/lib/python3.7/dist-packages/numpy-1.21.5.dist-info/\n",
            "   from /usr/local/lib/python3.7/dist-packages/~umpy-1.21.5.dist-info\n",
            "  Moving to /usr/local/lib/python3.7/dist-packages/numpy.libs/\n",
            "   from /usr/local/lib/python3.7/dist-packages/~umpy.libs\n",
            "  Moving to /usr/local/lib/python3.7/dist-packages/numpy/\n",
            "   from /usr/local/lib/python3.7/dist-packages/~umpy\n",
            "\u001b[31mERROR: Command errored out with exit status 1: /usr/bin/python3 -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-_0kqiv27/numpy_71a96e51dd5141abafbba59f8c337435/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-_0kqiv27/numpy_71a96e51dd5141abafbba59f8c337435/setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record /tmp/pip-record-ynhrujkc/install-record.txt --single-version-externally-managed --compile --install-headers /usr/local/include/python3.7/numpy Check the logs for full command output.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install madmom"
      ],
      "metadata": {
        "id": "dlFNKBVa0P-8",
        "outputId": "d30f6d98-7c37-4250-c557-ab577d076fce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting madmom\n",
            "  Downloading madmom-0.16.1.tar.gz (20.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 20.0 MB 1.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.13.4 in /usr/local/lib/python3.7/dist-packages (from madmom) (1.21.5)\n",
            "Requirement already satisfied: scipy>=0.16 in /usr/local/lib/python3.7/dist-packages (from madmom) (1.4.1)\n",
            "Requirement already satisfied: cython>=0.25 in /usr/local/lib/python3.7/dist-packages (from madmom) (0.29.28)\n",
            "Collecting mido>=1.2.8\n",
            "  Downloading mido-1.2.10-py2.py3-none-any.whl (51 kB)\n",
            "\u001b[K     |████████████████████████████████| 51 kB 6.2 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: madmom\n",
            "  Building wheel for madmom (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for madmom: filename=madmom-0.16.1-cp37-cp37m-linux_x86_64.whl size=20935891 sha256=093332dfe484af6deef0d84cb6a32e70888fee1c2f65b12910b4e3a1e7ca4659\n",
            "  Stored in directory: /root/.cache/pip/wheels/af/90/61/393ceef814b55b12d1b59b5ed3a2b2a3457a55d39b7363b975\n",
            "Successfully built madmom\n",
            "Installing collected packages: mido, madmom\n",
            "Successfully installed madmom-0.16.1 mido-1.2.10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!add-apt-repository ppa:mc3man/trusty-media\n",
        "!apt-get update\n",
        "!apt-get dist-upgrade\n",
        "!apt-get install ffmpeg"
      ],
      "metadata": {
        "id": "ucaAqV-q3vRN",
        "outputId": "f3515eeb-051e-45b3-b817-af592bd3d7cd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Upgraded, advanced or not normally available multimedia packages for Trusty\n",
            "Xenial users go here - https://launchpad.net/~mc3man/+archive/ubuntu/xerus-media\n",
            "\n",
            "*Please note that if using this ppa I would *not* try upgrading to 14.10/15.04, ect. Do a fresh install instead. The intent here is just for users wishing to stay on 14.04*\n",
            "\n",
            "If upgrading releases anyway use ppa-purge *First* -\n",
            "sudo ppa-purge  ppa:mc3man/trusty-media\n",
            "\n",
            "Also note that using this ppa then disabling may cause issue for installing i386 packages like used by wine. So once enabled leave enabled or purge before removing.\n",
            "\n",
            "Additionally if using apt-get * sudo  apt-get dist-upgrade will be needed* at times.(pay attention).  Otherwise package managers may be ok.\n",
            "\n",
            "So typically to enable & first use -\n",
            "sudo add-apt-repository ppa:mc3man/trusty-media\n",
            "sudo apt-get update\n",
            "sudo apt-get dist-upgrade\n",
            "\n",
            "A few notes:\n",
            "gstreamer0.10-ffmpeg - needed for some apps that still use gstreamer-0.10 & also provides h.264 in html5 decoding for firefox < 30.\n",
            "Note that Firefox 30 will support h.264 in html5 thru gstreamer1.0-libav & should be available soon\n",
            "\n",
            "A standalone ppa is here for gstreamer0.10-ffmpeg  -\n",
            "https://launchpad.net/~mc3man/+archive/ubuntu/gstffmpeg-keep\n",
            "\n",
            "Vlc: after upgrading please remove ~/.config/vlc folder to ensure proper runnning\n",
            "\n",
            "Totem - New - have added a --no-existing-session option to open a 2nd instance. Unity users can also find it in the totem quicklist\n",
            "\n",
            "Totem+grilo - it's quite possible this & RB+grilo will show in 14.04 by first point release, if so will probably remove. Also note some plugins work well, some don't at all, bit of a mess. Note that the youtube plugin is again broken, I'll not fix.\n",
            "\n",
            "rhythmbox+grilo - needs to be enabled in rhythmbox > tools > plugins\n",
            "Plus install grilo-plugins if not already\n",
            "\n",
            "mpv - has been removed as 14.04.4-lts requires higher libva than what's in 14.04 or in this ppa\n",
            "Available here with newer libva & i965 driver\n",
            "https://launchpad.net/~mc3man/+archive/mpv-tests\n",
            "\n",
            "mplayer - described here, note mencoder is not inc. & likely will not be, you may be able to use repo mencoder..\n",
            "https://launchpad.net/~mc3man/+archive/mplayer-test\n",
            "\n",
            "fdkaac (fdkaac-encoder) - described here\n",
            "https://launchpad.net/~mc3man/+archive/fdkaac-encoder\n",
            "\n",
            "x264 - for use with ffmpeg from here, supports both 8 & 10 bit encoding\n",
            "\n",
            "ffmpeg -\n",
            "a static build for use of the binaries, installed to /opt/ffmpeg\n",
            "binaries are symlinked in /usr/bin (ffmpeg, ffplay, ffprobe\n",
            "ffmpeg has nvenc enabled, ymmv depending on hardware/source files, ect.\n",
            "See for encoder names -\n",
            " ffmpeg -encoders 2>/dev/null | grep nvenc\n",
            "\n",
            "For info on using libfdk_aac see here -\n",
            "http://trac.ffmpeg.org/wiki/Encode/AAC\n",
            "\n",
            "Can be used for both 8 & 10 bit x264 encoding with this ppa's libx264, default is 8\n",
            "For 10 bit preload the 10 bit .so first in terminal, eg.,\n",
            "export LD_PRELOAD=/usr/lib/x86_64-linux-gnu/x264-10bit/libx264.so.142\n",
            "or\n",
            "export LD_PRELOAD=/usr/lib/i386-linux-gnu/x264-10bit/libx264.so.142\n",
            "\n",
            "libav - has fdkaac encoding enabled\n",
            "\n",
            "yasm -\n",
            " has been patched to improve compiling x265\n",
            "\n",
            "devede -\n",
            " can use either avconv or ffmpeg from here\n",
            " 1st choice for previewer is mplayer (version here is best\n",
            "\n",
            "K9copy -\n",
            "Mainly for ripping, as far as encoding there are better apps. If inclined to use for encoding then use mencoder as ffmpeg support is quite limited\n",
            "\n",
            "For rhythmbox users a wide range of plugins can be found here -\n",
            "https://launchpad.net/~fossfreedom/+archive/rhythmbox-plugins\n",
            "\n",
            "Abcde -\n",
            "ck. Suggested in synaptic for add. useful packages\n",
            "A guide to config is here -\n",
            "http://www.andrews-corner.org/abcde.html\n",
            "\n",
            "An excellent  audio recorder is available here -\n",
            "https://launchpad.net/~osmoma/+archive/audio-recorder\n",
            "\n",
            "A good blender ppa is here -\n",
            " https://launchpad.net/~irie/+archive/blender\n",
            "\n",
            "To further extend this ppa to libav11 check here -\n",
            "https://launchpad.net/~mc3man/+archive/ubuntu/testing6\n",
            "\n",
            "To repeat -\n",
            "*Please note that if using this ppa I would *not* try upgrading to 14.10/15.04, ect. Do a fresh install instead. The intent here is just for users wishing to stay on 14.04*\n",
            "If upgrading anyway use ppa-purge first -\n",
            "sudo ppa-purge  ppa:mc3man/trusty-media\n",
            "\n",
            "Also note that with apt-get a sudo apt-get dist-upgrade is needed for initial setup & with some package upgrades\n",
            " More info: https://launchpad.net/~mc3man/+archive/ubuntu/trusty-media\n",
            "Press [ENTER] to continue or Ctrl-c to cancel adding it.\n",
            "\n",
            "Get:1 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Ign:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:3 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "Ign:4 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release [696 B]\n",
            "Hit:6 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Hit:7 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
            "Get:8 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release.gpg [836 B]\n",
            "Hit:9 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Get:10 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Hit:11 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Get:12 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease [15.9 kB]\n",
            "Get:13 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,484 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Get:16 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2,660 kB]\n",
            "Hit:17 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Ign:18 http://ppa.launchpad.net/mc3man/trusty-media/ubuntu bionic InRelease\n",
            "Err:19 http://ppa.launchpad.net/mc3man/trusty-media/ubuntu bionic Release\n",
            "  404  Not Found [IP: 91.189.95.85 80]\n",
            "Get:20 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages [945 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu bionic-updates/multiverse amd64 Packages [29.8 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [3,098 kB]\n",
            "Get:23 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 Packages [45.3 kB]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,262 kB]\n",
            "Reading package lists... Done\n",
            "E: The repository 'http://ppa.launchpad.net/mc3man/trusty-media/ubuntu bionic Release' does not have a Release file.\n",
            "N: Updating from such a repository can't be done securely, and is therefore disabled by default.\n",
            "N: See apt-secure(8) manpage for repository creation and user configuration details.\n",
            "Hit:1 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Hit:2 http://security.ubuntu.com/ubuntu bionic-security InRelease\n",
            "Hit:3 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu bionic-updates InRelease\n",
            "Ign:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu bionic-backports InRelease\n",
            "Hit:7 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
            "Ign:8 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:9 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Hit:10 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Hit:11 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Hit:12 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Hit:13 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Ign:14 http://ppa.launchpad.net/mc3man/trusty-media/ubuntu bionic InRelease\n",
            "Err:15 http://ppa.launchpad.net/mc3man/trusty-media/ubuntu bionic Release\n",
            "  404  Not Found [IP: 91.189.95.85 80]\n",
            "Reading package lists... Done\n",
            "E: The repository 'http://ppa.launchpad.net/mc3man/trusty-media/ubuntu bionic Release' does not have a Release file.\n",
            "N: Updating from such a repository can't be done securely, and is therefore disabled by default.\n",
            "N: See apt-secure(8) manpage for repository creation and user configuration details.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "Calculating upgrade... Done\n",
            "The following packages have been kept back:\n",
            "  libcudnn8 libcudnn8-dev libnccl-dev libnccl2\n",
            "The following packages will be upgraded:\n",
            "  base-files binutils binutils-common binutils-x86-64-linux-gnu gnupg2 gzip\n",
            "  libaudit-common libaudit1 libbinutils libc-bin libcublas-dev libcublas10\n",
            "  libcudnn7 libcudnn7-dev libgnutls30 libhogweed4 libldap-2.4-2 libldap-common\n",
            "  liblz4-1 libnettle6 libp11-kit0 libpam-modules libpam-modules-bin\n",
            "  libpam-runtime libpam0g libsasl2-2 libsasl2-modules-db libseccomp2 libzstd1\n",
            "  linux-libc-dev login openssl passwd tar tzdata ubuntu-keyring\n",
            "36 upgraded, 0 newly installed, 0 to remove and 4 not upgraded.\n",
            "Need to get 449 MB of archives.\n",
            "After this operation, 69.7 MB of additional disk space will be used.\n",
            "Get:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  libcublas10 10.2.3.254-1 [43.1 MB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 base-files amd64 10.1ubuntu2.11 [60.4 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 gzip amd64 1.6-5ubuntu1.1 [89.8 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 login amd64 1:4.5-1ubuntu2.2 [308 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 tar amd64 1.29b-2ubuntu0.3 [234 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libc-bin amd64 2.27-3ubuntu1.5 [638 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libaudit-common all 1:2.8.2-1ubuntu1.1 [4,068 B]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libaudit1 amd64 1:2.8.2-1ubuntu1.1 [38.7 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libpam0g amd64 1.1.8-3.6ubuntu2.18.04.3 [55.0 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libpam-modules-bin amd64 1.1.8-3.6ubuntu2.18.04.3 [40.3 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libpam-modules amd64 1.1.8-3.6ubuntu2.18.04.3 [252 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 liblz4-1 amd64 0.0~r131-2ubuntu3.1 [48.5 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libpam-runtime all 1.1.8-3.6ubuntu2.18.04.3 [37.1 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libzstd1 amd64 1.3.3+dfsg-2ubuntu1.2 [189 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 passwd amd64 1:4.5-1ubuntu2.2 [818 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libnettle6 amd64 3.4.1-0ubuntu0.18.04.1 [111 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libhogweed4 amd64 3.4.1-0ubuntu0.18.04.1 [140 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libp11-kit0 amd64 0.23.9-2ubuntu0.1 [187 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libgnutls30 amd64 3.5.18-1ubuntu1.5 [646 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libseccomp2 amd64 2.5.1-1ubuntu1~18.04.2 [43.0 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 ubuntu-keyring all 2018.09.18.1~18.04.2 [22.3 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 openssl amd64 1.1.1-1ubuntu2.1~18.04.15 [614 kB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 tzdata all 2022a-0ubuntu0.18.04 [190 kB]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 binutils-x86-64-linux-gnu amd64 2.30-21ubuntu1~18.04.7 [1,839 kB]\n",
            "Get:25 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 binutils-common amd64 2.30-21ubuntu1~18.04.7 [197 kB]\n",
            "Get:26 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 binutils amd64 2.30-21ubuntu1~18.04.7 [3,388 B]\n",
            "Get:27 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libbinutils amd64 2.30-21ubuntu1~18.04.7 [489 kB]\n",
            "Get:28 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libsasl2-modules-db amd64 2.1.27~101-g0780600+dfsg-3ubuntu2.4 [15.0 kB]\n",
            "Get:29 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libsasl2-2 amd64 2.1.27~101-g0780600+dfsg-3ubuntu2.4 [49.2 kB]\n",
            "Get:30 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libldap-common all 2.4.45+dfsg-1ubuntu1.10 [15.8 kB]\n",
            "Get:31 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libldap-2.4-2 amd64 2.4.45+dfsg-1ubuntu1.10 [154 kB]\n",
            "Get:32 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 linux-libc-dev amd64 4.15.0-173.182 [990 kB]\n",
            "Get:33 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 gnupg2 all 2.2.4-1ubuntu1.4 [5,292 B]\n",
            "Get:34 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  libcublas-dev 10.2.3.254-1 [42.4 MB]\n",
            "Get:35 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  libcudnn7-dev 7.6.5.32-1+cuda10.2 [165 MB]\n",
            "Get:36 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  libcudnn7 7.6.5.32-1+cuda10.2 [189 MB]\n",
            "Fetched 449 MB in 9s (50.9 MB/s)\n",
            "Extracting templates from packages: 100%\n",
            "Preconfiguring packages ...\n",
            "(Reading database ... 156210 files and directories currently installed.)\n",
            "Preparing to unpack .../base-files_10.1ubuntu2.11_amd64.deb ...\n",
            "Unpacking base-files (10.1ubuntu2.11) over (10.1ubuntu2.10) ...\n",
            "Setting up base-files (10.1ubuntu2.11) ...\n",
            "Installing new version of config file /etc/issue ...\n",
            "Installing new version of config file /etc/issue.net ...\n",
            "Installing new version of config file /etc/lsb-release ...\n",
            "(Reading database ... 156210 files and directories currently installed.)\n",
            "Preparing to unpack .../gzip_1.6-5ubuntu1.1_amd64.deb ...\n",
            "Unpacking gzip (1.6-5ubuntu1.1) over (1.6-5ubuntu1) ...\n",
            "Setting up gzip (1.6-5ubuntu1.1) ...\n",
            "(Reading database ... 156210 files and directories currently installed.)\n",
            "Preparing to unpack .../login_1%3a4.5-1ubuntu2.2_amd64.deb ...\n",
            "Unpacking login (1:4.5-1ubuntu2.2) over (1:4.5-1ubuntu2) ...\n",
            "Setting up login (1:4.5-1ubuntu2.2) ...\n",
            "(Reading database ... 156210 files and directories currently installed.)\n",
            "Preparing to unpack .../tar_1.29b-2ubuntu0.3_amd64.deb ...\n",
            "Unpacking tar (1.29b-2ubuntu0.3) over (1.29b-2ubuntu0.1) ...\n",
            "Setting up tar (1.29b-2ubuntu0.3) ...\n",
            "update-alternatives: warning: forcing reinstallation of alternative /usr/sbin/rmt-tar because link group rmt is broken\n",
            "(Reading database ... 156210 files and directories currently installed.)\n",
            "Preparing to unpack .../libc-bin_2.27-3ubuntu1.5_amd64.deb ...\n",
            "Unpacking libc-bin (2.27-3ubuntu1.5) over (2.27-3ubuntu1.3) ...\n",
            "Setting up libc-bin (2.27-3ubuntu1.5) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n",
            "(Reading database ... 156210 files and directories currently installed.)\n",
            "Preparing to unpack .../libaudit-common_1%3a2.8.2-1ubuntu1.1_all.deb ...\n",
            "Unpacking libaudit-common (1:2.8.2-1ubuntu1.1) over (1:2.8.2-1ubuntu1) ...\n",
            "Setting up libaudit-common (1:2.8.2-1ubuntu1.1) ...\n",
            "(Reading database ... 156210 files and directories currently installed.)\n",
            "Preparing to unpack .../libaudit1_1%3a2.8.2-1ubuntu1.1_amd64.deb ...\n",
            "Unpacking libaudit1:amd64 (1:2.8.2-1ubuntu1.1) over (1:2.8.2-1ubuntu1) ...\n",
            "Setting up libaudit1:amd64 (1:2.8.2-1ubuntu1.1) ...\n",
            "(Reading database ... 156210 files and directories currently installed.)\n",
            "Preparing to unpack .../libpam0g_1.1.8-3.6ubuntu2.18.04.3_amd64.deb ...\n",
            "Unpacking libpam0g:amd64 (1.1.8-3.6ubuntu2.18.04.3) over (1.1.8-3.6ubuntu2.18.04.2) ...\n",
            "Setting up libpam0g:amd64 (1.1.8-3.6ubuntu2.18.04.3) ...\n",
            "(Reading database ... 156210 files and directories currently installed.)\n",
            "Preparing to unpack .../libpam-modules-bin_1.1.8-3.6ubuntu2.18.04.3_amd64.deb ...\n",
            "Unpacking libpam-modules-bin (1.1.8-3.6ubuntu2.18.04.3) over (1.1.8-3.6ubuntu2.18.04.2) ...\n",
            "Setting up libpam-modules-bin (1.1.8-3.6ubuntu2.18.04.3) ...\n",
            "(Reading database ... 156212 files and directories currently installed.)\n",
            "Preparing to unpack .../libpam-modules_1.1.8-3.6ubuntu2.18.04.3_amd64.deb ...\n",
            "Unpacking libpam-modules:amd64 (1.1.8-3.6ubuntu2.18.04.3) over (1.1.8-3.6ubuntu2.18.04.2) ...\n",
            "Setting up libpam-modules:amd64 (1.1.8-3.6ubuntu2.18.04.3) ...\n",
            "(Reading database ... 156216 files and directories currently installed.)\n",
            "Preparing to unpack .../liblz4-1_0.0~r131-2ubuntu3.1_amd64.deb ...\n",
            "Unpacking liblz4-1:amd64 (0.0~r131-2ubuntu3.1) over (0.0~r131-2ubuntu3) ...\n",
            "Setting up liblz4-1:amd64 (0.0~r131-2ubuntu3.1) ...\n",
            "(Reading database ... 156216 files and directories currently installed.)\n",
            "Preparing to unpack .../libpam-runtime_1.1.8-3.6ubuntu2.18.04.3_all.deb ...\n",
            "Unpacking libpam-runtime (1.1.8-3.6ubuntu2.18.04.3) over (1.1.8-3.6ubuntu2.18.04.2) ...\n",
            "Setting up libpam-runtime (1.1.8-3.6ubuntu2.18.04.3) ...\n",
            "(Reading database ... 156216 files and directories currently installed.)\n",
            "Preparing to unpack .../libzstd1_1.3.3+dfsg-2ubuntu1.2_amd64.deb ...\n",
            "Unpacking libzstd1:amd64 (1.3.3+dfsg-2ubuntu1.2) over (1.3.3+dfsg-2ubuntu1.1) ...\n",
            "Setting up libzstd1:amd64 (1.3.3+dfsg-2ubuntu1.2) ...\n",
            "(Reading database ... 156216 files and directories currently installed.)\n",
            "Preparing to unpack .../passwd_1%3a4.5-1ubuntu2.2_amd64.deb ...\n",
            "Unpacking passwd (1:4.5-1ubuntu2.2) over (1:4.5-1ubuntu2) ...\n",
            "Setting up passwd (1:4.5-1ubuntu2.2) ...\n",
            "(Reading database ... 156216 files and directories currently installed.)\n",
            "Preparing to unpack .../libnettle6_3.4.1-0ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking libnettle6:amd64 (3.4.1-0ubuntu0.18.04.1) over (3.4-1) ...\n",
            "Setting up libnettle6:amd64 (3.4.1-0ubuntu0.18.04.1) ...\n",
            "(Reading database ... 156216 files and directories currently installed.)\n",
            "Preparing to unpack .../libhogweed4_3.4.1-0ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking libhogweed4:amd64 (3.4.1-0ubuntu0.18.04.1) over (3.4-1) ...\n",
            "Setting up libhogweed4:amd64 (3.4.1-0ubuntu0.18.04.1) ...\n",
            "(Reading database ... 156216 files and directories currently installed.)\n",
            "Preparing to unpack .../libp11-kit0_0.23.9-2ubuntu0.1_amd64.deb ...\n",
            "Unpacking libp11-kit0:amd64 (0.23.9-2ubuntu0.1) over (0.23.9-2) ...\n",
            "Setting up libp11-kit0:amd64 (0.23.9-2ubuntu0.1) ...\n",
            "(Reading database ... 156216 files and directories currently installed.)\n",
            "Preparing to unpack .../libgnutls30_3.5.18-1ubuntu1.5_amd64.deb ...\n",
            "Unpacking libgnutls30:amd64 (3.5.18-1ubuntu1.5) over (3.5.18-1ubuntu1.4) ...\n",
            "Setting up libgnutls30:amd64 (3.5.18-1ubuntu1.5) ...\n",
            "(Reading database ... 156216 files and directories currently installed.)\n",
            "Preparing to unpack .../libseccomp2_2.5.1-1ubuntu1~18.04.2_amd64.deb ...\n",
            "Unpacking libseccomp2:amd64 (2.5.1-1ubuntu1~18.04.2) over (2.4.3-1ubuntu3.18.04.3) ...\n",
            "Setting up libseccomp2:amd64 (2.5.1-1ubuntu1~18.04.2) ...\n",
            "(Reading database ... 156216 files and directories currently installed.)\n",
            "Preparing to unpack .../ubuntu-keyring_2018.09.18.1~18.04.2_all.deb ...\n",
            "Unpacking ubuntu-keyring (2018.09.18.1~18.04.2) over (2018.09.18.1~18.04.0) ...\n",
            "Setting up ubuntu-keyring (2018.09.18.1~18.04.2) ...\n",
            "(Reading database ... 156216 files and directories currently installed.)\n",
            "Preparing to unpack .../00-openssl_1.1.1-1ubuntu2.1~18.04.15_amd64.deb ...\n",
            "Unpacking openssl (1.1.1-1ubuntu2.1~18.04.15) over (1.1.1-1ubuntu2.1~18.04.7) ...\n",
            "Preparing to unpack .../01-tzdata_2022a-0ubuntu0.18.04_all.deb ...\n",
            "Unpacking tzdata (2022a-0ubuntu0.18.04) over (2021e-0ubuntu0.18.04) ...\n",
            "Preparing to unpack .../02-binutils-x86-64-linux-gnu_2.30-21ubuntu1~18.04.7_amd64.deb ...\n",
            "Unpacking binutils-x86-64-linux-gnu (2.30-21ubuntu1~18.04.7) over (2.30-21ubuntu1~18.04.4) ...\n",
            "Preparing to unpack .../03-binutils-common_2.30-21ubuntu1~18.04.7_amd64.deb ...\n",
            "Unpacking binutils-common:amd64 (2.30-21ubuntu1~18.04.7) over (2.30-21ubuntu1~18.04.4) ...\n",
            "Preparing to unpack .../04-binutils_2.30-21ubuntu1~18.04.7_amd64.deb ...\n",
            "Unpacking binutils (2.30-21ubuntu1~18.04.7) over (2.30-21ubuntu1~18.04.4) ...\n",
            "Preparing to unpack .../05-libbinutils_2.30-21ubuntu1~18.04.7_amd64.deb ...\n",
            "Unpacking libbinutils:amd64 (2.30-21ubuntu1~18.04.7) over (2.30-21ubuntu1~18.04.4) ...\n",
            "Preparing to unpack .../06-libcublas10_10.2.3.254-1_amd64.deb ...\n",
            "Unpacking libcublas10 (10.2.3.254-1) over (10.2.1.243-1) ...\n",
            "Preparing to unpack .../07-libcublas-dev_10.2.3.254-1_amd64.deb ...\n",
            "Unpacking libcublas-dev (10.2.3.254-1) over (10.2.1.243-1) ...\n",
            "Preparing to unpack .../08-libcudnn7-dev_7.6.5.32-1+cuda10.2_amd64.deb ...\n",
            "update-alternatives: removing manually selected alternative - switching libcudnn to auto mode\n",
            "update-alternatives: using /usr/include/x86_64-linux-gnu/cudnn_v8.h to provide /usr/include/cudnn.h (libcudnn) in auto mode\n",
            "Unpacking libcudnn7-dev (7.6.5.32-1+cuda10.2) over (7.6.5.32-1+cuda10.1) ...\n",
            "Preparing to unpack .../09-libcudnn7_7.6.5.32-1+cuda10.2_amd64.deb ...\n",
            "Unpacking libcudnn7 (7.6.5.32-1+cuda10.2) over (7.6.5.32-1+cuda10.1) ...\n",
            "Preparing to unpack .../10-libsasl2-modules-db_2.1.27~101-g0780600+dfsg-3ubuntu2.4_amd64.deb ...\n",
            "Unpacking libsasl2-modules-db:amd64 (2.1.27~101-g0780600+dfsg-3ubuntu2.4) over (2.1.27~101-g0780600+dfsg-3ubuntu2.1) ...\n",
            "Preparing to unpack .../11-libsasl2-2_2.1.27~101-g0780600+dfsg-3ubuntu2.4_amd64.deb ...\n",
            "Unpacking libsasl2-2:amd64 (2.1.27~101-g0780600+dfsg-3ubuntu2.4) over (2.1.27~101-g0780600+dfsg-3ubuntu2.1) ...\n",
            "Preparing to unpack .../12-libldap-common_2.4.45+dfsg-1ubuntu1.10_all.deb ...\n",
            "Unpacking libldap-common (2.4.45+dfsg-1ubuntu1.10) over (2.4.45+dfsg-1ubuntu1.8) ...\n",
            "Preparing to unpack .../13-libldap-2.4-2_2.4.45+dfsg-1ubuntu1.10_amd64.deb ...\n",
            "Unpacking libldap-2.4-2:amd64 (2.4.45+dfsg-1ubuntu1.10) over (2.4.45+dfsg-1ubuntu1.8) ...\n",
            "Preparing to unpack .../14-linux-libc-dev_4.15.0-173.182_amd64.deb ...\n",
            "Unpacking linux-libc-dev:amd64 (4.15.0-173.182) over (4.15.0-128.131) ...\n",
            "Preparing to unpack .../15-gnupg2_2.2.4-1ubuntu1.4_all.deb ...\n",
            "Unpacking gnupg2 (2.2.4-1ubuntu1.4) over (2.2.4-1ubuntu1.3) ...\n",
            "Setting up libcudnn7 (7.6.5.32-1+cuda10.2) ...\n",
            "Setting up libldap-common (2.4.45+dfsg-1ubuntu1.10) ...\n",
            "Setting up tzdata (2022a-0ubuntu0.18.04) ...\n",
            "\n",
            "Current default time zone: 'Etc/UTC'\n",
            "Local time is now:      Fri Mar 25 16:21:37 UTC 2022.\n",
            "Universal Time is now:  Fri Mar 25 16:21:37 UTC 2022.\n",
            "Run 'dpkg-reconfigure tzdata' if you wish to change it.\n",
            "\n",
            "Setting up libsasl2-modules-db:amd64 (2.1.27~101-g0780600+dfsg-3ubuntu2.4) ...\n",
            "Setting up linux-libc-dev:amd64 (4.15.0-173.182) ...\n",
            "Setting up libsasl2-2:amd64 (2.1.27~101-g0780600+dfsg-3ubuntu2.4) ...\n",
            "Setting up libcudnn7-dev (7.6.5.32-1+cuda10.2) ...\n",
            "update-alternatives: using /usr/include/x86_64-linux-gnu/cudnn_v7.h to provide /usr/include/cudnn.h (libcudnn) in manual mode\n",
            "Setting up binutils-common:amd64 (2.30-21ubuntu1~18.04.7) ...\n",
            "Setting up gnupg2 (2.2.4-1ubuntu1.4) ...\n",
            "Setting up libcublas10 (10.2.3.254-1) ...\n",
            "Setting up libcublas-dev (10.2.3.254-1) ...\n",
            "Setting up libldap-2.4-2:amd64 (2.4.45+dfsg-1ubuntu1.10) ...\n",
            "Setting up openssl (1.1.1-1ubuntu2.1~18.04.15) ...\n",
            "Setting up libbinutils:amd64 (2.30-21ubuntu1~18.04.7) ...\n",
            "Setting up binutils-x86-64-linux-gnu (2.30-21ubuntu1~18.04.7) ...\n",
            "Setting up binutils (2.30-21ubuntu1~18.04.7) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.5) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for mime-support (3.60ubuntu1) ...\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:3.4.8-0ubuntu0.2).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 4 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python build_mtt.py"
      ],
      "metadata": {
        "id": "UYlmPgZN4zz9",
        "outputId": "957f6770-b8ec-4d8c-8154-274267b83070",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start building the dataset.\n",
            "100 audios are written into \"test-0041-of-0043.seq.tfrecord\".\n",
            "100 audios are written into \"test-0038-of-0043.seq.tfrecord\".\n",
            "101 audios are written into \"test-0013-of-0043.seq.tfrecord\".\n",
            "101 audios are written into \"test-0002-of-0043.seq.tfrecord\".\n",
            "101 audios are written into \"test-0003-of-0043.seq.tfrecord\".\n",
            "102 audios are written into \"val-0007-of-0015.tfrecord\".\n",
            "102 audios are written into \"val-0013-of-0015.tfrecord\".\n",
            "101 audios are written into \"val-0014-of-0015.tfrecord\".\n",
            "100 audios are written into \"train-0109-of-0152.tfrecord\".\n",
            "101 audios are written into \"test-0028-of-0043.seq.tfrecord\".\n",
            "101 audios are written into \"test-0021-of-0043.seq.tfrecord\".\n",
            "100 audios are written into \"test-0037-of-0043.seq.tfrecord\".\n",
            "100 audios are written into \"train-0069-of-0152.tfrecord\".\n",
            "101 audios are written into \"train-0048-of-0152.tfrecord\".\n",
            "100 audios are written into \"train-0091-of-0152.tfrecord\".\n",
            "100 audios are written into \"train-0138-of-0152.tfrecord\".\n",
            "100 audios are written into \"train-0103-of-0152.tfrecord\".\n",
            "100 audios are written into \"train-0131-of-0152.tfrecord\".\n",
            "100 audios are written into \"train-0050-of-0152.tfrecord\".\n",
            "100 audios are written into \"train-0077-of-0152.tfrecord\".\n",
            "100 audios are written into \"train-0059-of-0152.tfrecord\".\n",
            "100 audios are written into \"train-0083-of-0152.tfrecord\".\n",
            "100 audios are written into \"train-0089-of-0152.tfrecord\".\n",
            "101 audios are written into \"train-0001-of-0152.tfrecord\".\n",
            "101 audios are written into \"train-0015-of-0152.tfrecord\".\n",
            "101 audios are written into \"train-0033-of-0152.tfrecord\".\n",
            "100 audios are written into \"train-0076-of-0152.tfrecord\".\n",
            "101 audios are written into \"train-0016-of-0152.tfrecord\".\n",
            "101 audios are written into \"train-0023-of-0152.tfrecord\".\n",
            "100 audios are written into \"train-0105-of-0152.tfrecord\".\n",
            "101 audios are written into \"train-0008-of-0152.tfrecord\".\n",
            "101 audios are written into \"train-0030-of-0152.tfrecord\".\n",
            "101 audios are written into \"train-0018-of-0152.tfrecord\".\n",
            "101 audios are written into \"train-0038-of-0152.tfrecord\".\n",
            "100 audios are written into \"train-0086-of-0152.tfrecord\".\n",
            "100 audios are written into \"train-0106-of-0152.tfrecord\".\n",
            "100 audios are written into \"train-0097-of-0152.tfrecord\".\n",
            "101 audios are written into \"train-0002-of-0152.tfrecord\".\n",
            "100 audios are written into \"train-0075-of-0152.tfrecord\".\n",
            "100 audios are written into \"train-0061-of-0152.tfrecord\".\n",
            "100 audios are written into \"train-0135-of-0152.tfrecord\".\n",
            "101 audios are written into \"train-0049-of-0152.tfrecord\".\n",
            "100 audios are written into \"train-0085-of-0152.tfrecord\".\n",
            "100 audios are written into \"train-0115-of-0152.tfrecord\".\n",
            "101 audios are written into \"test-0000-of-0043.seq.tfrecord\".\n",
            "101 audios are written into \"test-0010-of-0043.seq.tfrecord\".\n",
            "101 audios are written into \"test-0006-of-0043.seq.tfrecord\".\n",
            "101 audios are written into \"test-0031-of-0043.seq.tfrecord\".\n",
            "101 audios are written into \"test-0011-of-0043.seq.tfrecord\".\n",
            "101 audios are written into \"test-0019-of-0043.seq.tfrecord\".\n",
            "101 audios are written into \"test-0012-of-0043.seq.tfrecord\".\n",
            "101 audios are written into \"test-0020-of-0043.seq.tfrecord\".\n",
            "101 audios are written into \"train-0011-of-0152.tfrecord\".\n",
            "100 audios are written into \"train-0136-of-0152.tfrecord\".\n",
            "100 audios are written into \"train-0066-of-0152.tfrecord\".\n",
            "100 audios are written into \"train-0096-of-0152.tfrecord\".\n",
            "101 audios are written into \"train-0041-of-0152.tfrecord\".\n",
            "100 audios are written into \"train-0124-of-0152.tfrecord\".\n",
            "100 audios are written into \"train-0053-of-0152.tfrecord\".\n",
            "100 audios are written into \"train-0098-of-0152.tfrecord\".\n",
            "101 audios are written into \"train-0005-of-0152.tfrecord\".\n",
            "101 audios are written into \"train-0003-of-0152.tfrecord\".\n",
            "100 audios are written into \"train-0113-of-0152.tfrecord\".\n",
            "100 audios are written into \"train-0071-of-0152.tfrecord\".\n",
            "100 audios are written into \"train-0082-of-0152.tfrecord\".\n",
            "101 audios are written into \"test-0014-of-0043.seq.tfrecord\".\n",
            "101 audios are written into \"test-0007-of-0043.seq.tfrecord\".\n",
            "100 audios are written into \"test-0034-of-0043.seq.tfrecord\".\n",
            "100 audios are written into \"train-0073-of-0152.tfrecord\".\n",
            "100 audios are written into \"train-0128-of-0152.tfrecord\".\n",
            "102 audios are written into \"val-0008-of-0015.tfrecord\".\n",
            "102 audios are written into \"val-0003-of-0015.tfrecord\".\n",
            "102 audios are written into \"val-0005-of-0015.tfrecord\".\n",
            "100 audios are written into \"test-0036-of-0043.seq.tfrecord\".\n",
            "101 audios are written into \"test-0024-of-0043.seq.tfrecord\".\n",
            "100 audios are written into \"train-0080-of-0152.tfrecord\".\n",
            "100 audios are written into \"train-0060-of-0152.tfrecord\".\n",
            "101 audios are written into \"test-0022-of-0043.seq.tfrecord\".\n",
            "100 audios are written into \"train-0112-of-0152.tfrecord\".\n",
            "100 audios are written into \"train-0051-of-0152.tfrecord\".\n",
            "101 audios are written into \"train-0013-of-0152.tfrecord\".\n",
            "100 audios are written into \"train-0123-of-0152.tfrecord\".\n",
            "100 audios are written into \"train-0140-of-0152.tfrecord\".\n",
            "101 audios are written into \"train-0035-of-0152.tfrecord\".\n",
            "102 audios are written into \"val-0012-of-0015.tfrecord\".\n",
            "102 audios are written into \"val-0009-of-0015.tfrecord\".\n",
            "100 audios are written into \"train-0107-of-0152.tfrecord\".\n",
            "101 audios are written into \"train-0022-of-0152.tfrecord\".\n",
            "100 audios are written into \"train-0064-of-0152.tfrecord\".\n",
            "100 audios are written into \"train-0111-of-0152.tfrecord\".\n",
            "100 audios are written into \"train-0058-of-0152.tfrecord\".\n",
            "100 audios are written into \"train-0055-of-0152.tfrecord\".\n",
            "100 audios are written into \"train-0129-of-0152.tfrecord\".\n",
            "101 audios are written into \"train-0009-of-0152.tfrecord\".\n",
            "100 audios are written into \"train-0139-of-0152.tfrecord\".\n",
            "101 audios are written into \"train-0042-of-0152.tfrecord\".\n",
            "100 audios are written into \"train-0119-of-0152.tfrecord\".\n",
            "101 audios are written into \"train-0026-of-0152.tfrecord\".\n",
            "101 audios are written into \"train-0000-of-0152.tfrecord\".\n",
            "102 audios are written into \"val-0000-of-0015.tfrecord\".\n",
            "102 audios are written into \"val-0002-of-0015.tfrecord\".\n",
            "102 audios are written into \"val-0006-of-0015.tfrecord\".\n",
            "101 audios are written into \"train-0019-of-0152.tfrecord\".\n",
            "Process Process-1:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"build_mtt.py\", line 49, in process_audio_files\n",
            "    examples = audio_to_examples(audio_path, labels, sample_rate, num_samples)\n",
            "  File \"/content/drive/MyDrive/NN/resemul/data/preprocessing/audio_processing.py\", line 126, in audio_to_examples\n",
            "    segments = _audio_to_segments(filename, sample_rate=sample_rate, num_samples=num_samples)\n",
            "  File \"/content/drive/MyDrive/NN/resemul/data/preprocessing/audio_processing.py\", line 85, in _audio_to_segments\n",
            "    sig = Signal(filename, sample_rate=sample_rate, dtype=np.float32, stop=29, num_channels=1)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/madmom/audio/signal.py\", line 598, in __new__\n",
            "    dtype=dtype)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/madmom/io/audio.py\", line 633, in load_audio_file\n",
            "    raise LoadAudioFileError(error)\n",
            "madmom.io.audio.LoadAudioFileError: \"All attempts to load audio file '/content/drive/MyDrive/NN/MagnaTagATune/dataset/mp3/9/american_baroque-dances_and_suites_of_rameau_and_couperin-25-le_petit_rien_xiveme_ordre_couperin-88-117.mp3' failed.\"\n",
            "100 audios are written into \"train-0052-of-0152.tfrecord\".\n",
            "101 audios are written into \"train-0027-of-0152.tfrecord\".\n",
            "100 audios are written into \"train-0150-of-0152.tfrecord\".\n",
            "100 audios are written into \"train-0100-of-0152.tfrecord\".\n",
            "101 audios are written into \"train-0007-of-0152.tfrecord\".\n",
            "100 audios are written into \"train-0067-of-0152.tfrecord\".\n",
            "100 audios are written into \"train-0078-of-0152.tfrecord\".\n",
            "Process Process-2:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"build_mtt.py\", line 49, in process_audio_files\n",
            "    examples = audio_to_examples(audio_path, labels, sample_rate, num_samples)\n",
            "  File \"/content/drive/MyDrive/NN/resemul/data/preprocessing/audio_processing.py\", line 126, in audio_to_examples\n",
            "    segments = _audio_to_segments(filename, sample_rate=sample_rate, num_samples=num_samples)\n",
            "  File \"/content/drive/MyDrive/NN/resemul/data/preprocessing/audio_processing.py\", line 85, in _audio_to_segments\n",
            "    sig = Signal(filename, sample_rate=sample_rate, dtype=np.float32, stop=29, num_channels=1)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/madmom/audio/signal.py\", line 598, in __new__\n",
            "    dtype=dtype)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/madmom/io/audio.py\", line 633, in load_audio_file\n",
            "    raise LoadAudioFileError(error)\n",
            "madmom.io.audio.LoadAudioFileError: \"All attempts to load audio file '/content/drive/MyDrive/NN/MagnaTagATune/dataset/mp3/8/jacob_heringman-josquin_des_prez_lute_settings-19-gintzler__pater_noster-204-233.mp3' failed.\"\n",
            "Done.\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
            "    send_bytes(obj)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
            "    self._send_bytes(m[offset:offset + size])\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 398, in _send_bytes\n",
            "    self._send(buf)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
            "    n = write(self._handle, buf)\n",
            "BrokenPipeError: [Errno 32] Broken pipe\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
            "    send_bytes(obj)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
            "    self._send_bytes(m[offset:offset + size])\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 397, in _send_bytes\n",
            "    self._send(header)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
            "    n = write(self._handle, buf)\n",
            "BrokenPipeError: [Errno 32] Broken pipe\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
            "    send_bytes(obj)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
            "    self._send_bytes(m[offset:offset + size])\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 397, in _send_bytes\n",
            "    self._send(header)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
            "    n = write(self._handle, buf)\n",
            "BrokenPipeError: [Errno 32] Broken pipe\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
            "    send_bytes(obj)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
            "    self._send_bytes(m[offset:offset + size])\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 397, in _send_bytes\n",
            "    self._send(header)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
            "    n = write(self._handle, buf)\n",
            "BrokenPipeError: [Errno 32] Broken pipe\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
            "    send_bytes(obj)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
            "    self._send_bytes(m[offset:offset + size])\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 397, in _send_bytes\n",
            "    self._send(header)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
            "    n = write(self._handle, buf)\n",
            "BrokenPipeError: [Errno 32] Broken pipe\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
            "    send_bytes(obj)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
            "    self._send_bytes(m[offset:offset + size])\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 397, in _send_bytes\n",
            "    self._send(header)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
            "    n = write(self._handle, buf)\n",
            "BrokenPipeError: [Errno 32] Broken pipe\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
            "    send_bytes(obj)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
            "    self._send_bytes(m[offset:offset + size])\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 397, in _send_bytes\n",
            "    self._send(header)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
            "    n = write(self._handle, buf)\n",
            "BrokenPipeError: [Errno 32] Broken pipe\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
            "    send_bytes(obj)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
            "    self._send_bytes(m[offset:offset + size])\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 397, in _send_bytes\n",
            "    self._send(header)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
            "    n = write(self._handle, buf)\n",
            "BrokenPipeError: [Errno 32] Broken pipe\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
            "    send_bytes(obj)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
            "    self._send_bytes(m[offset:offset + size])\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 397, in _send_bytes\n",
            "    self._send(header)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
            "    n = write(self._handle, buf)\n",
            "BrokenPipeError: [Errno 32] Broken pipe\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
            "    send_bytes(obj)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
            "    self._send_bytes(m[offset:offset + size])\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 397, in _send_bytes\n",
            "    self._send(header)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
            "    n = write(self._handle, buf)\n",
            "BrokenPipeError: [Errno 32] Broken pipe\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
            "    send_bytes(obj)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
            "    self._send_bytes(m[offset:offset + size])\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 397, in _send_bytes\n",
            "    self._send(header)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
            "    n = write(self._handle, buf)\n",
            "BrokenPipeError: [Errno 32] Broken pipe\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
            "    send_bytes(obj)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
            "    self._send_bytes(m[offset:offset + size])\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 397, in _send_bytes\n",
            "    self._send(header)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
            "    n = write(self._handle, buf)\n",
            "BrokenPipeError: [Errno 32] Broken pipe\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
            "    send_bytes(obj)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
            "    self._send_bytes(m[offset:offset + size])\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 397, in _send_bytes\n",
            "    self._send(header)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
            "    n = write(self._handle, buf)\n",
            "BrokenPipeError: [Errno 32] Broken pipe\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
            "    send_bytes(obj)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
            "    self._send_bytes(m[offset:offset + size])\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 397, in _send_bytes\n",
            "    self._send(header)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
            "    n = write(self._handle, buf)\n",
            "BrokenPipeError: [Errno 32] Broken pipe\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
            "    send_bytes(obj)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
            "    self._send_bytes(m[offset:offset + size])\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 397, in _send_bytes\n",
            "    self._send(header)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
            "    n = write(self._handle, buf)\n",
            "BrokenPipeError: [Errno 32] Broken pipe\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
            "    send_bytes(obj)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
            "    self._send_bytes(m[offset:offset + size])\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 397, in _send_bytes\n",
            "    self._send(header)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
            "    n = write(self._handle, buf)\n",
            "BrokenPipeError: [Errno 32] Broken pipe\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
            "    send_bytes(obj)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
            "    self._send_bytes(m[offset:offset + size])\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 397, in _send_bytes\n",
            "    self._send(header)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
            "    n = write(self._handle, buf)\n",
            "BrokenPipeError: [Errno 32] Broken pipe\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
            "    send_bytes(obj)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
            "    self._send_bytes(m[offset:offset + size])\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 397, in _send_bytes\n",
            "    self._send(header)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
            "    n = write(self._handle, buf)\n",
            "BrokenPipeError: [Errno 32] Broken pipe\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
            "    send_bytes(obj)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
            "    self._send_bytes(m[offset:offset + size])\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 397, in _send_bytes\n",
            "    self._send(header)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
            "    n = write(self._handle, buf)\n",
            "BrokenPipeError: [Errno 32] Broken pipe\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
            "    send_bytes(obj)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
            "    self._send_bytes(m[offset:offset + size])\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 397, in _send_bytes\n",
            "    self._send(header)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
            "    n = write(self._handle, buf)\n",
            "BrokenPipeError: [Errno 32] Broken pipe\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
            "    send_bytes(obj)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
            "    self._send_bytes(m[offset:offset + size])\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 397, in _send_bytes\n",
            "    self._send(header)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
            "    n = write(self._handle, buf)\n",
            "BrokenPipeError: [Errno 32] Broken pipe\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
            "    send_bytes(obj)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
            "    self._send_bytes(m[offset:offset + size])\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 397, in _send_bytes\n",
            "    self._send(header)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
            "    n = write(self._handle, buf)\n",
            "BrokenPipeError: [Errno 32] Broken pipe\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
            "    send_bytes(obj)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
            "    self._send_bytes(m[offset:offset + size])\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 397, in _send_bytes\n",
            "    self._send(header)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
            "    n = write(self._handle, buf)\n",
            "BrokenPipeError: [Errno 32] Broken pipe\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
            "    send_bytes(obj)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
            "    self._send_bytes(m[offset:offset + size])\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 397, in _send_bytes\n",
            "    self._send(header)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
            "    n = write(self._handle, buf)\n",
            "BrokenPipeError: [Errno 32] Broken pipe\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
            "    send_bytes(obj)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
            "    self._send_bytes(m[offset:offset + size])\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 397, in _send_bytes\n",
            "    self._send(header)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
            "    n = write(self._handle, buf)\n",
            "BrokenPipeError: [Errno 32] Broken pipe\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
            "    send_bytes(obj)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
            "    self._send_bytes(m[offset:offset + size])\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 397, in _send_bytes\n",
            "    self._send(header)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
            "    n = write(self._handle, buf)\n",
            "BrokenPipeError: [Errno 32] Broken pipe\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
            "    send_bytes(obj)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
            "    self._send_bytes(m[offset:offset + size])\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 397, in _send_bytes\n",
            "    self._send(header)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
            "    n = write(self._handle, buf)\n",
            "BrokenPipeError: [Errno 32] Broken pipe\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py --data-dir /content/drive/MyDrive/NN/MagnaTagATune/dataset/tfrecord --train-dir /content/drive/MyDrive/NN/MagnaTagATune/dataset/trainlogs"
      ],
      "metadata": {
        "id": "_jZhx08gIVJ6",
        "outputId": "60394ada-9254-432e-f96b-1515f2a8b44f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"train.py\", line 3, in <module>\n",
            "    from keras.optimizers import SGD\n",
            "ImportError: cannot import name 'SGD' from 'keras.optimizers' (/usr/local/lib/python3.7/dist-packages/keras/optimizers.py)\n"
          ]
        }
      ]
    }
  ]
}